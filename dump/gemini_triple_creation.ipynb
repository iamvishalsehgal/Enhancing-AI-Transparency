{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7625c86-7352-439a-a913-53e5c0603410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, ModelCard\n",
    "import json, string, time\n",
    "from datetime import datetime\n",
    "import re\n",
    "import traceback\n",
    "import google.generativeai as genai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b18890-39e9-4249-b76a-f004e719c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "HFTOKEN = \"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\"\n",
    "GTOKEN = \"AIzaSyB8HMqIGvscURWPF75CwnZlXnFFsGh0Vlg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d58047f-849d-4536-ac7e-c58e78c66344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def clean_identifier(text):\n",
    "    \"\"\"Clean text for URI safety\"\"\"\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "    return re.sub(r'[^a-zA-Z0-9-]', '', str(text).replace(' ', '-'))[:50]\n",
    "\n",
    "def get_dynamic_mapping(entity_key):\n",
    "    \"\"\"Generate predicate and class URIs dynamically\"\"\"\n",
    "    clean_key = ''.join([w.capitalize() for w in re.split('[^a-zA-Z0-9]', entity_key)])\n",
    "    return {\n",
    "        \"class_uri\": f\"{clean_key}\",\n",
    "        \"predicate_uri\": f\"has{clean_key}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3fc587-e975-4ea4-bbe8-ba1c40a07d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hf_entities(text):\n",
    "    \"\"\"Open-ended entity extraction using LLMs\"\"\"\n",
    "    try:\n",
    "        prompt = f\"\"\"Extract ALL technical metadata from this model card as JSON.\n",
    "Include: architectures, licenses, datasets, metrics, hardware, training details,\n",
    "evaluation scores, libraries used, and any other technical specifications.\n",
    "Use simple key-value pairs. Example:\n",
    "{{\n",
    "  \"license\": \"MIT\",\n",
    "  \"architecture\": \"Transformer\",\n",
    "  \"trainingData\": [\"Common Crawl\", \"Wikipedia\"]\n",
    "}}\n",
    "\n",
    "Model card text:\n",
    "{text[:10000]}\"\"\"\n",
    "        genai.configure(api_key=GTOKEN)\n",
    "        model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "        response = model.generate_content(prompt)\n",
    "        json_str = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        return json.loads(json_str)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Extraction error: {str(e)}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7897d490-a52f-469c-8076-3357e0a517cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hf_triples(model_data):\n",
    "    triples = []\n",
    "    model_uri = f\"{clean_identifier(model_data['id'])}\"\n",
    "    \n",
    "    # Base type assertion\n",
    "    triples.append({\"s\": model_uri, \"p\": \"rdf:type\", \"o\": \"Model\"})\n",
    "\n",
    "    if \"entities\" in model_data:\n",
    "        for key, value in model_data[\"entities\"].items():\n",
    "            if not value or key.lower() in ['id', 'model']:\n",
    "                continue\n",
    "\n",
    "            # Get dynamic ontology mapping\n",
    "            mapping = get_dynamic_mapping(key)\n",
    "            values = value if isinstance(value, list) else [value]\n",
    "\n",
    "            for val in values:\n",
    "                if pd.isna(val) or str(val).lower() in ['none', 'null', 'nan']:\n",
    "                    continue\n",
    "\n",
    "                # Create unique entity URI\n",
    "                entity_uri = f\"{model_uri}-{clean_identifier(key)}-{clean_identifier(str(val))}\"\n",
    "                \n",
    "                # Add triples\n",
    "                triples.extend([\n",
    "                    {\"s\": model_uri, \"p\": mapping['predicate_uri'], \"o\": entity_uri},\n",
    "                    {\"s\": entity_uri, \"p\": \"rdf:type\", \"o\": mapping['class_uri']},\n",
    "                    {\"s\": entity_uri, \"p\": \"dul:hasParameterDataValue\", \"o\": str(val)},\n",
    "                    {\"s\": mapping['class_uri'], \"p\": \"rdfs:subClassOf\", \"o\": \"Component\"}\n",
    "                ])\n",
    "    \n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87ea035b-087f-48e9-8662-b11eecfe5572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_huggingface_models(limit=20):\n",
    "    api = HfApi(token=HFTOKEN)\n",
    "    models = list(api.list_models(sort=\"downloads\", direction=-1, limit=limit))\n",
    "    all_triples = []\n",
    "\n",
    "    for idx, model in enumerate(models):\n",
    "        try:\n",
    "            # Get model card\n",
    "            card = ModelCard.load(model.modelId, token=HFTOKEN)\n",
    "            entities = extract_hf_entities(card.text)\n",
    "            \n",
    "            if not entities:\n",
    "                print(f\"Skipping {model.modelId} - no entities found\")\n",
    "                continue\n",
    "\n",
    "            # Generate triples\n",
    "            model_data = {\"id\": model.modelId, \"entities\": entities}\n",
    "            triples = generate_hf_triples(model_data)\n",
    "            all_triples.extend(triples)\n",
    "\n",
    "            # Progress reporting\n",
    "            if idx % 5 == 0:\n",
    "                print(f\"Processed {idx+1}/{len(models)}: {model.modelId}\")\n",
    "                print(f\"Generated {len(triples)} triples from {len(entities)} entities\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {model.modelId}: {str(e)}\")\n",
    "\n",
    "    # Save results\n",
    "    with open(\"dynamic_triples.json\", \"w\") as f:\n",
    "        json.dump(all_triples, f, indent=2)\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\n=== STATISTICS ===\")\n",
    "    print(f\"Total models processed: {len(models)}\")\n",
    "    print(f\"Total triples generated: {len(all_triples)}\")\n",
    "    \n",
    "    return all_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27f374a4-00de-4eb5-bddd-a4671931bae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DYNAMIC TRIPLE EXTRACTION STARTED ===\n",
      "Processed 1/50: timm/mobilenetv3_small_100.lamb_in1k\n",
      "Generated 69 triples from 15 entities\n",
      "Processed 6/50: google-bert/bert-base-uncased\n",
      "Generated 89 triples from 11 entities\n",
      "Processed 11/50: Bingsu/adetailer\n",
      "Generated 73 triples from 6 entities\n",
      "Processed 16/50: pyannote/wespeaker-voxceleb-resnet34-LM\n",
      "Generated 53 triples from 13 entities\n",
      "Processed 21/50: distilbert/distilbert-base-uncased\n",
      "Generated 105 triples from 18 entities\n",
      "Extraction error: Extra data: line 4 column 1 (char 5)\n",
      "Skipping unslothai/1 - no entities found\n",
      "Processed 31/50: kresnik/wav2vec2-large-xlsr-korean\n",
      "Generated 57 triples from 11 entities\n",
      "Processed 36/50: google/vit-base-patch16-224\n",
      "Generated 77 triples from 17 entities\n",
      "Processed 41/50: google-t5/t5-base\n",
      "Generated 153 triples from 13 entities\n",
      "Extraction error: Expecting value: line 14 column 6 (char 1332)\n",
      "Skipping bartowski/DeepSeek-R1-Distill-Qwen-14B-GGUF - no entities found\n",
      "Processed 46/50: facebook/contriever-msmarco\n",
      "Generated 53 triples from 11 entities\n",
      "\n",
      "=== STATISTICS ===\n",
      "Total models processed: 50\n",
      "Total triples generated: 4152\n",
      "\n",
      "=== COMPLETED ===\n",
      "Final triple count: 4152\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"=== DYNAMIC TRIPLE EXTRACTION STARTED ===\")\n",
    "    triples = process_huggingface_models(limit=50)\n",
    "    print(\"\\n=== COMPLETED ===\")\n",
    "    print(f\"Final triple count: {len(triples)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
