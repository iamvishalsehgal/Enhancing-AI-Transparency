{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "153972c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating SPARQL query...\n",
      "\n",
      "Generated SPARQL:\n",
      " PREFIX mcro: <http://purl.obolibrary.org/obo/mcro.owl#>\n",
      "PREFIX dul: <http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#>\n",
      "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
      "\n",
      "SELECT DISTINCT ?model WHERE {\n",
      "    ?model a mcro:Model .\n",
      "}\n",
      "\n",
      "Executing query...\n",
      "\n",
      "Results:\n",
      " - mcro.owl#Falconsainsfwimagedetection\n",
      "- mcro.owl#dima806fairfaceageimagedetection\n",
      "- mcro.owl#googlebertbertbaseuncased\n",
      "- mcro.owl#openaiclipvitlargepatch14\n",
      "- mcro.owl#sentencetransformersallMiniLML6v2\n",
      "- mcro.owl#timmmobilenetv3small100lambin1k\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "from rdflib import Graph\n",
    "import google.generativeai as genai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- Configuration ---\n",
    "GTOKEN = \"AIzaSyDQQY8FmOW6erFivgwsHjAdf419PYddNis\"\n",
    "genai.configure(api_key=GTOKEN)\n",
    "GRAPHDB_ENDPOINT = \"http://Vishals-MacBook-Air.local:7200/repositories/thesis\"\n",
    "TBOX_PATH = \"model_card.ttl\"\n",
    "ENCODER_MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "GEMINI_MODEL = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# --- Load T-Box ---\n",
    "kg = Graph()\n",
    "kg.parse(TBOX_PATH, format=\"turtle\")\n",
    "\n",
    "# --- KG Prefix Extraction ---\n",
    "PREFIXES = \"\"\"\n",
    "PREFIX mcro: <http://purl.obolibrary.org/obo/mcro.owl#>\n",
    "PREFIX dul: <http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\"\"\"\n",
    "\n",
    "# --- T-Box Query Functions ---\n",
    "def get_classes_properties():\n",
    "    query = \"\"\"\n",
    "    SELECT DISTINCT ?resource ?label ?comment WHERE {\n",
    "        { ?resource a rdfs:Class }\n",
    "        UNION\n",
    "        { ?resource a rdf:Property }\n",
    "        OPTIONAL { ?resource rdfs:label ?label }\n",
    "        OPTIONAL { ?resource rdfs:comment ?comment }\n",
    "    }\n",
    "    \"\"\"\n",
    "    return kg.query(query)\n",
    "\n",
    "# --- Core Functions ---\n",
    "def get_kg_subgraph(nl_question: str) -> str:\n",
    "    tokens = set(re.findall(r'\\b\\w+\\b', nl_question.lower()))\n",
    "    matched_resources = []\n",
    "    \n",
    "    # Add class/property matching\n",
    "    for row in get_classes_properties():\n",
    "        uri = str(row.resource)\n",
    "        label = str(row.label).lower() if row.label else uri.split(\"#\")[-1].lower()\n",
    "        comment = str(row.comment).lower() if row.comment else \"\"\n",
    "        \n",
    "        # Exact match boosting\n",
    "        if any(token == label.split(\"#\")[-1] for token in tokens):\n",
    "            score = 2.0\n",
    "        else:\n",
    "            score = sum(1 for token in tokens if token in label or token in comment)\n",
    "        \n",
    "        if score > 0:\n",
    "            matched_resources.append({\n",
    "                \"uri\": uri,\n",
    "                \"label\": label,\n",
    "                \"comment\": comment,\n",
    "                \"score\": score\n",
    "            })\n",
    "    \n",
    "    # Sort by relevance\n",
    "    matched_resources.sort(key=lambda x: -x['score'])\n",
    "    \n",
    "    return \"\\n\".join([\n",
    "        f\"- {res['label']} ({res['comment']})\" \n",
    "        for res in matched_resources[:5]\n",
    "    ])\n",
    "\n",
    "def get_similar_examples(nl_question: str, k=3) -> str:\n",
    "    EXAMPLE_DATASET = [\n",
    "        {\n",
    "            \"nl\": \"Show all models\",\n",
    "            \"sparql\": f\"\"\"\n",
    "            {PREFIXES}\n",
    "            SELECT DISTINCT ?model WHERE {{\n",
    "                ?model a mcro:Model .\n",
    "            }}\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"nl\": \"Show models using Vision Transformer architecture\",\n",
    "            \"sparql\": f\"\"\"\n",
    "            {PREFIXES}\n",
    "            SELECT ?model WHERE {{\n",
    "                ?model mcro:hasArchitecture ?arch .\n",
    "                ?arch dul:hasParameterDataValue \"Vision Transformer (ViT)\" .\n",
    "            }}\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"nl\": \"Find models with accuracy over 90%\",\n",
    "            \"sparql\": f\"\"\"\n",
    "            {PREFIXES}\n",
    "            SELECT ?model ?accuracy WHERE {{\n",
    "                ?model mcro:hasEvaluationScores ?scores .\n",
    "                ?scores dul:hasParameterDataValue ?data .\n",
    "                BIND(REPLACE(STR(?data), '[^0-9.]+', '') AS ?acc_str)\n",
    "                BIND(xsd:decimal(?acc_str) AS ?accuracy)\n",
    "                FILTER(?accuracy > 90)\n",
    "            }}\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    query_embedding = ENCODER_MODEL.encode(nl_question)\n",
    "    example_embeddings = [ENCODER_MODEL.encode(ex[\"nl\"]) for ex in EXAMPLE_DATASET]\n",
    "    \n",
    "    similarities = cosine_similarity([query_embedding], example_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    \n",
    "    examples = []\n",
    "    for i in top_indices:\n",
    "        examples.append(f\"Question: {EXAMPLE_DATASET[i]['nl']}\\nSPARQL: {EXAMPLE_DATASET[i]['sparql']}\")\n",
    "    \n",
    "    return \"\\n\".join(examples)\n",
    "\n",
    "def text_to_sparql(nl_question: str) -> str:\n",
    "    kg_context = get_kg_subgraph(nl_question)\n",
    "    examples = get_similar_examples(nl_question)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are a SPARQL expert. Generate a query for this KG schema:\n",
    "\n",
    "KG Schema:\n",
    "{kg_context}\n",
    "\n",
    "Prefixes:\n",
    "{PREFIXES}\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Question: {nl_question}\n",
    "\n",
    "Rules:\n",
    "1. Use SELECT DISTINCT for model queries\n",
    "2. mcro:Model is the base class for ML models\n",
    "3. For numeric filters: BIND(REPLACE(STR(?value), '[^0-9.]', '') AS ?num)\n",
    "4. Use FILTER with xsd:decimal for comparisons\n",
    "5. Always include PREFIX declarations\n",
    "6. Only return valid SPARQL in ```sparql blocks\n",
    "\"\"\"\n",
    "    \n",
    "    response = GEMINI_MODEL.generate_content(prompt)\n",
    "    raw_sparql = response.text\n",
    "    \n",
    "    if \"```sparql\" in raw_sparql:\n",
    "        return re.search(r\"```sparql(.*?)```\", raw_sparql, re.DOTALL).group(1).strip()\n",
    "    return raw_sparql\n",
    "\n",
    "def execute_sparql(sparql: str) -> dict:\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            GRAPHDB_ENDPOINT,\n",
    "            headers={\n",
    "                \"Accept\": \"application/sparql-results+json\",\n",
    "                \"Content-Type\": \"application/sparql-query\"\n",
    "            },\n",
    "            data=sparql.encode('utf-8'),\n",
    "            timeout=30  # Increased timeout\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        error_details = {\n",
    "            \"status_code\": e.response.status_code,\n",
    "            \"message\": e.response.text,\n",
    "            \"query\": sparql\n",
    "        }\n",
    "        return {\"error\": error_details}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"query\": sparql}\n",
    "    \n",
    "def sparql_to_nl(results: dict) -> str:\n",
    "    if \"error\" in results:\n",
    "        error = results[\"error\"]\n",
    "        return f\"Error {error.get('status_code', '')}: {error.get('message', 'Unknown error')}\"\n",
    "    \n",
    "    bindings = results.get(\"results\", {}).get(\"bindings\", [])\n",
    "    if not bindings:\n",
    "        return \"No results found\"\n",
    "    \n",
    "    output = []\n",
    "    for item in bindings:\n",
    "        model_uri = item.get(\"model\", {}).get(\"value\", \"\")\n",
    "        model_name = model_uri.split(\"/\")[-1].replace(\"mcro_\", \"\")\n",
    "        \n",
    "        # Handle additional fields\n",
    "        accuracy = item.get(\"accuracy\", {}).get(\"value\", \"\")\n",
    "        if accuracy:\n",
    "            model_name += f\" (Accuracy: {accuracy}%)\"\n",
    "        \n",
    "        output.append(f\"- {model_name}\")\n",
    "    \n",
    "    return \"\\n\".join(sorted(output)) if output else \"No models found\"\n",
    "\n",
    "# --- Main Workflow ---\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"Show all models\"\n",
    "    \n",
    "    print(\"Generating SPARQL query...\")\n",
    "    sparql = text_to_sparql(question)\n",
    "    print(\"\\nGenerated SPARQL:\\n\", sparql)\n",
    "    \n",
    "    if \"SELECT\" in sparql.upper():\n",
    "        print(\"\\nExecuting query...\")\n",
    "        results = execute_sparql(sparql)\n",
    "        answer = sparql_to_nl(results)\n",
    "        print(\"\\nResults:\\n\", answer)\n",
    "    else:\n",
    "        print(\"Invalid SPARQL query generated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
