{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56239e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading triples from extracted_triples.json...\n",
      "✅ Loaded 284 triples\n",
      "\n",
      "\n",
      "Processing batch 1 (1-50)\n",
      "\n",
      "Processing batch 2 (51-100)\n",
      "\n",
      "Processing batch 3 (101-150)\n",
      "\n",
      "Processing batch 4 (151-200)\n",
      "\n",
      "Processing batch 5 (201-250)\n",
      "\n",
      "Processing batch 6 (251-284)\n",
      "\n",
      "📊 SEMANTIC ACCURACY REPORT\n",
      "==================================================\n",
      "Overall Semantic Accuracy: 0.0%\n",
      "Average Match Confidence: 95.0/100\n",
      "Total Valid Matches: 0\n",
      "Total Invalid Matches: 29\n",
      "Unmapped Models: 136\n",
      "Validation Errors: 1\n",
      "\n",
      "📈 PREDICATE-SPECIFIC ACCURACY:\n",
      "dul:hasParameterDataValue 0.0% (0/83)\n",
      "hasArchitecture      0.0% (0/4)\n",
      "hasBatchSize         0.0% (0/2)\n",
      "hasClasses           0.0% (0/2)\n",
      "hasDataset           0.0% (0/15)\n",
      "hasDownstreamTask    0.0% (0/3)\n",
      "hasEvaluationAccuracy 0.0% (0/1)\n",
      "hasEvaluationMetric  0.0% (0/1)\n",
      "hasEvaluationResult  0.0% (0/3)\n",
      "hasFineTuningObjective 0.0% (0/1)\n",
      "hasFormat            0.0% (0/1)\n",
      "hasHyperparameter    0.0% (0/2)\n",
      "hasIntendedUse       0.0% (0/1)\n",
      "hasLanguage          0.0% (0/1)\n",
      "hasLearningRate      0.0% (0/2)\n",
      "hasMetric            0.0% (0/1)\n",
      "hasModelCreator      0.0% (0/1)\n",
      "hasModelDate         0.0% (0/1)\n",
      "hasModelType         0.0% (0/1)\n",
      "hasOptimizer         0.0% (0/1)\n",
      "hasParadigm          0.0% (0/1)\n",
      "hasParameterQuantity 0.0% (0/1)\n",
      "hasPreTrainingDataset 0.0% (0/1)\n",
      "hasTrainingData      0.0% (0/32)\n",
      "hasTrainingDataset   0.0% (0/1)\n",
      "hasTrainingProcedure 0.0% (0/3)\n",
      "rdf:type             0.0% (0/93)\n",
      "rdfs:subClassOf      0.0% (0/25)\n",
      "\n",
      "🔍 CONFIDENCE DISTRIBUTION:\n",
      "Highest Confidence: 97.0\n",
      "Lowest Confidence: 93.0\n",
      "Confidence Threshold: 70%\n",
      "\n",
      "📄 Full report saved to validation_results.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "from getpass import getpass\n",
    "from huggingface_hub import HfApi\n",
    "from functools import lru_cache\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# ================== CONFIGURATION ==================\n",
    "HF_TOKEN = getpass(\"Enter Hugging Face Token (or set HF_TOKEN environment variable): \")\n",
    "\n",
    "# Initialize Hugging Face API client\n",
    "hf_api = HfApi(token=HF_TOKEN)\n",
    "\n",
    "# Ontology prefix to remove\n",
    "ONTOLOGY_PREFIX = \"http://purl.obolibrary.org/obo/mcro.owl#\"\n",
    "\n",
    "# Model name mapping cache\n",
    "MODEL_NAME_CACHE = {}\n",
    "\n",
    "# Output file\n",
    "RESULTS_FILE = \"validation_results.json\"\n",
    "# ===================================================\n",
    "\n",
    "def load_and_clean_triples(file_path):\n",
    "    \"\"\"Load JSON triples and remove ontology prefix\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            raw_triples = json.load(f)\n",
    "        \n",
    "        cleaned_triples = []\n",
    "        for t in raw_triples:\n",
    "            cleaned_triple = {\n",
    "                key: value.replace(ONTOLOGY_PREFIX, '') \n",
    "                for key, value in t.items()\n",
    "            }\n",
    "            cleaned_triples.append(cleaned_triple)\n",
    "        \n",
    "        return cleaned_triples\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ ERROR: File {file_path} not found\")\n",
    "        return []\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, max=10))\n",
    "def auto_map_model(local_name, threshold=70):\n",
    "    \"\"\"Search HF models via direct API call\"\"\"\n",
    "    if local_name in MODEL_NAME_CACHE:\n",
    "        return MODEL_NAME_CACHE[local_name]\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://huggingface.co/api/models?search={local_name[:30]}\"\n",
    "        response = requests.get(url, headers={\"Authorization\": f\"Bearer {HF_TOKEN}\"})\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"API error: {response.status_code}\")\n",
    "            \n",
    "        results = response.json()\n",
    "        \n",
    "        if not results:\n",
    "            MODEL_NAME_CACHE[local_name] = (None, 0)\n",
    "            return None, 0\n",
    "\n",
    "        # Extract model IDs and match similarity\n",
    "        candidates = [(m[\"id\"], m[\"id\"].lower()) for m in results]\n",
    "        matches = [m[1] for m in candidates]\n",
    "\n",
    "        best_match = process.extractOne(local_name.lower(), matches)\n",
    "\n",
    "        if best_match and best_match[1] >= threshold:\n",
    "            try:\n",
    "                match_index = matches.index(best_match[0])\n",
    "                hf_model_id = candidates[match_index][0]\n",
    "                MODEL_NAME_CACHE[local_name] = (hf_model_id, best_match[1])\n",
    "                return MODEL_NAME_CACHE[local_name]\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        MODEL_NAME_CACHE[local_name] = (None, 0)\n",
    "        return None, 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Search error for '{local_name}': {e}\")\n",
    "        MODEL_NAME_CACHE[local_name] = (None, 0)\n",
    "        return None, 0\n",
    "\n",
    "def extract_numeric_value(metadata, keyword):\n",
    "    \"\"\"Extract numeric values from description/text fields\"\"\"\n",
    "    text = str(metadata.get(\"description\", \"\") + \n",
    "              \" \" + str(metadata.get(\"modelId\"))).lower()\n",
    "    \n",
    "    import re\n",
    "    patterns = {\n",
    "        \"batch_size\": r\"batch[\\s_-]?size.*?(\\d+)\",\n",
    "        \"learning_rate\": r\"(?:lr|learning[\\s_-]?rate).*?([0-9.eE\\-]+)\",\n",
    "        \"epochs\": r\"epoch[s]?:?\\s*(\\d+)\"\n",
    "    }\n",
    "    \n",
    "    if pattern := patterns.get(keyword):\n",
    "        if match := re.search(pattern, text):\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "# Map ontology predicates to Hugging Face API fields\n",
    "PREDICATE_MAP = {\n",
    "    # Direct field mappings\n",
    "    \"hasLicense\": (\"license\", lambda m: m.get(\"license\")),\n",
    "    \"hasTask\": (\"pipeline_tag\", lambda m: m.get(\"pipeline_tag\")),\n",
    "    \"hasAuthor\": (\"author\", lambda m: m.get(\"author\")),\n",
    "    \"hasDownloadCount\": (\"downloads\", lambda m: m.get(\"downloads\")),\n",
    "    \n",
    "    # Custom field handlers\n",
    "    \"hasArchitecture\": (\"architecture\", lambda m: m.get(\"modelId\").split(\"/\")[-1].lower()),\n",
    "    \"hasDataset\": (\"dataset_name\", lambda m: str(m.get(\"dataset_name\", \"\"))),\n",
    "    \"hasTrainingDataset\": (\"train_dataset\", lambda m: str(m.get(\"dataset_name\", \"\"))),\n",
    "    \"hasClasses\": (\"classification\", lambda m: \"classification\" in str(m.get(\"tags\", []))),\n",
    "    \"hasBatchSize\": (\"batch_size\", lambda m: extract_numeric_value(m, \"batch_size\")),\n",
    "    \"hasLearningRate\": (\"learning_rate\", lambda m: extract_numeric_value(m, \"learning_rate\")),\n",
    "    \"hasEpochs\": (\"epochs\", lambda m: extract_numeric_value(m, \"epochs\")),\n",
    "    \"hasMetric\": (\"metric\", lambda m: any(tag in str(m.get(\"tags\", [])).lower() for tag in [\"accuracy\", \"f1\", \"bleu\"])),\n",
    "    \"hasEvaluationAccuracy\": (\"accuracy\", lambda m: \"accuracy\" in str(m.get(\"metrics\", []))),\n",
    "    \"hasLanguage\": (\"language\", lambda m: \"en\" in str(m.get(\"tags\", []))),\n",
    "    \"hasModelDate\": (\"date\", lambda m: m.get(\"last_modified\").split(\"T\")[0]),  # YYYY-MM-DD format\n",
    "}\n",
    "\n",
    "def validate_hf_triple(triple, max_retries=3):\n",
    "    \"\"\"Validate triples against Hugging Face API when possible\"\"\"\n",
    "    subject = triple['s']\n",
    "    predicate = triple['p']\n",
    "    expected_value = triple['o'].lower()\n",
    "    \n",
    "    # Skip ontology-only statements\n",
    "    if predicate in [\"rdf:type\", \"rdfs:subClassOf\"]:\n",
    "        return {\n",
    "            **triple,\n",
    "            \"status\": \"SKIPPED\",\n",
    "            \"reason\": \"Ontology statement\"\n",
    "        }\n",
    "    \n",
    "    # Get mapping info\n",
    "    mapping_info = PREDICATE_MAP.get(predicate)\n",
    "    if not mapping_info:\n",
    "        return {\n",
    "            **triple,\n",
    "            \"status\": \"UNMAPPED\",\n",
    "            \"reason\": f\"Unknown predicate: {predicate}\"\n",
    "        }\n",
    "    \n",
    "    field_name, value_extractor = mapping_info\n",
    "    \n",
    "    # Map model name\n",
    "    if subject in MODEL_NAME_CACHE:\n",
    "        hf_model_id, confidence = MODEL_NAME_CACHE[subject]\n",
    "    else:\n",
    "        hf_model_id, confidence = auto_map_model(subject)\n",
    "    \n",
    "    if not hf_model_id:\n",
    "        return {\n",
    "            **triple,\n",
    "            \"status\": \"UNMAPPED\",\n",
    "            \"reason\": f\"No HF mapping found for '{subject}' (confidence: {confidence})\"\n",
    "        }\n",
    "    \n",
    "    # Get model metadata\n",
    "    try:\n",
    "        metadata = safe_get_metadata(hf_model_id)\n",
    "        if not metadata:\n",
    "            return {\n",
    "                **triple,\n",
    "                \"status\": \"ERROR\",\n",
    "                \"reason\": \"Failed to fetch metadata after retries\"\n",
    "            }\n",
    "            \n",
    "        actual_value = value_extractor(metadata)\n",
    "        result = str(expected_value).lower() == str(actual_value).lower() if actual_value else False\n",
    "        \n",
    "        return {\n",
    "            **triple,\n",
    "            \"status\": result,\n",
    "            \"actual_value\": actual_value,\n",
    "            \"field\": field_name,\n",
    "            \"hf_model_id\": hf_model_id,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            **triple,\n",
    "            \"status\": \"ERROR\",\n",
    "            \"reason\": str(e),\n",
    "            \"hf_model_id\": hf_model_id\n",
    "        }\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, max=10))\n",
    "def safe_get_metadata(model_id):\n",
    "    \"\"\"Get model metadata with retry logic\"\"\"\n",
    "    url = f\"https://huggingface.co/api/models/{model_id}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "    \n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    \n",
    "    if response.status_code == 429:  # Rate limited\n",
    "        wait = int(response.headers.get('Retry-After', '5'))\n",
    "        print(f\"⏳ Rate limited. Waiting {wait}s...\")\n",
    "        time.sleep(wait)\n",
    "        raise Exception(\"Rate limited\")\n",
    "        \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"HTTP {response.status_code}: {response.text[:100]}\")\n",
    "        \n",
    "    return response.json()\n",
    "\n",
    "def batch_validate_triples(triples, batch_size=50, max_workers=10):\n",
    "    \"\"\"Process triples in batches with parallel execution\"\"\"\n",
    "    results = []\n",
    "    total = len(triples)\n",
    "    \n",
    "    for i in range(0, total, batch_size):\n",
    "        batch = triples[i:i+batch_size]\n",
    "        print(f\"\\nProcessing batch {i//batch_size + 1} ({i+1}-{min(i+batch_size, total)})\")\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = []\n",
    "            for triple in batch:\n",
    "                futures.append(executor.submit(validate_hf_triple, triple))\n",
    "            \n",
    "            for future in futures:\n",
    "                results.append(future.result())\n",
    "                \n",
    "        time.sleep(5)  # Rate limit buffer\n",
    "        \n",
    "    return results\n",
    "\n",
    "def generate_report(results):\n",
    "    \"\"\"Generate summary report focusing on accuracy metrics\"\"\"\n",
    "    valid = [r for r in results if r[\"status\"] is True]\n",
    "    invalid = [r for r in results if r[\"status\"] is False]\n",
    "    skipped = [r for r in results if r[\"status\"] == \"SKIPPED\"]\n",
    "    unmapped = [r for r in results if r[\"status\"] == \"UNMAPPED\"]\n",
    "    errors = [r for r in results if r[\"status\"] == \"ERROR\"]\n",
    "    \n",
    "    # Calculate match confidence statistics\n",
    "    mapped_results = [r for r in results if r.get(\"confidence\", 0) > 0]\n",
    "    confidences = [r[\"confidence\"] for r in mapped_results]\n",
    "    avg_confidence = sum(confidences)/len(confidences) if confidences else 0\n",
    "    \n",
    "    # Calculate accuracy by predicate\n",
    "    predicate_stats = {}\n",
    "    for r in results:\n",
    "        pred = r['p']\n",
    "        if pred not in predicate_stats:\n",
    "            predicate_stats[pred] = {\"total\": 0, \"valid\": 0}\n",
    "        predicate_stats[pred][\"total\"] += 1\n",
    "        if r[\"status\"] is True:\n",
    "            predicate_stats[pred][\"valid\"] += 1\n",
    "\n",
    "    # Calculate semantic accuracy (excluding skipped)\n",
    "    semantic_results = [r for r in results if r[\"status\"] not in [\"SKIPPED\", \"UNMAPPED\", \"ERROR\"]]\n",
    "    semantic_valid = [r for r in semantic_results if r[\"status\"] is True]\n",
    "    semantic_accuracy = len(semantic_valid)/len(semantic_results) * 100 if semantic_results else 0\n",
    "    \n",
    "    # Print detailed accuracy report\n",
    "    print(\"\\n📊 SEMANTIC ACCURACY REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Overall Semantic Accuracy: {semantic_accuracy:.1f}%\")\n",
    "    print(f\"Average Match Confidence: {avg_confidence:.1f}/100\")\n",
    "    print(f\"Total Valid Matches: {len(valid)}\")\n",
    "    print(f\"Total Invalid Matches: {len(invalid)}\")\n",
    "    print(f\"Unmapped Models: {len(unmapped)}\")\n",
    "    print(f\"Validation Errors: {len(errors)}\")\n",
    "    \n",
    "    print(\"\\n📈 PREDICATE-SPECIFIC ACCURACY:\")\n",
    "    for pred, stats in sorted(predicate_stats.items()):\n",
    "        acc = stats[\"valid\"]/stats[\"total\"] * 100\n",
    "        print(f\"{pred:<20} {acc:.1f}% ({stats['valid']}/{stats['total']})\")\n",
    "    \n",
    "    print(\"\\n🔍 CONFIDENCE DISTRIBUTION:\")\n",
    "    print(f\"Highest Confidence: {max(confidences) if confidences else 0:.1f}\")\n",
    "    print(f\"Lowest Confidence: {min(confidences) if confidences else 0:.1f}\")\n",
    "    print(f\"Confidence Threshold: 70%\")\n",
    "\n",
    "    # Save detailed results with accuracy metrics\n",
    "    report_data = {\n",
    "        \"summary\": {\n",
    "            \"overall_semantic_accuracy\": semantic_accuracy,\n",
    "            \"average_match_confidence\": avg_confidence,\n",
    "            \"validation_stats\": {\n",
    "                \"valid\": len(valid),\n",
    "                \"invalid\": len(invalid),\n",
    "                \"skipped\": len(skipped),\n",
    "                \"unmapped\": len(unmapped),\n",
    "                \"errors\": len(errors)\n",
    "            },\n",
    "            \"predicate_accuracy\": {\n",
    "                pred: {\n",
    "                    \"accuracy\": stats[\"valid\"]/stats[\"total\"] * 100,\n",
    "                    \"count\": stats[\"total\"]\n",
    "                } for pred, stats in predicate_stats.items()\n",
    "            },\n",
    "            \"confidence_stats\": {\n",
    "                \"average\": avg_confidence,\n",
    "                \"highest\": max(confidences) if confidences else 0,\n",
    "                \"lowest\": min(confidences) if confidences else 0,\n",
    "                \"threshold\": 70\n",
    "            }\n",
    "        },\n",
    "        \"detailed_results\": results\n",
    "    }\n",
    "    \n",
    "    with open(RESULTS_FILE, \"w\") as f:\n",
    "        json.dump(report_data, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n📄 Full report saved to {RESULTS_FILE}\")\n",
    "\n",
    "def main():\n",
    "    # Load triples\n",
    "    TRIPLES_FILE = \"extracted_triples.json\"\n",
    "    print(f\"🔄 Loading triples from {TRIPLES_FILE}...\")\n",
    "    \n",
    "    triples = load_and_clean_triples(TRIPLES_FILE)\n",
    "    \n",
    "    if not triples:\n",
    "        print(\"No triples loaded. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"✅ Loaded {len(triples)} triples\\n\")\n",
    "    \n",
    "    # Validate triples\n",
    "    results = batch_validate_triples(triples)\n",
    "    \n",
    "    # Generate final report\n",
    "    generate_report(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
