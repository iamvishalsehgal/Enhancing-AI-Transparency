{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e797a6f-09e2-4d91-b375-7fe3993600bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRIPLE GENERATION STARTED ===\n",
      "Processed 1/10: timm/mobilenetv3_small_100.lamb_in1k\n",
      "Generated 13 triples from 4 entities\n",
      "Processed 6/10: openai/clip-vit-large-patch14\n",
      "Generated 121 triples from 6 entities\n",
      "\n",
      "=== STATISTICS ===\n",
      "Total models processed: 10\n",
      "Total triples generated: 392\n",
      "\n",
      "=== COMPLETED ===\n",
      "Final triple count: 392\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, ModelCard\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Authentication\n",
    "HFTOKEN = \"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\"\n",
    "GTOKEN = \"AIzaSyCLwWkDW03zjzVKUQf3ui5wgcreVJdsMbw\"\n",
    "\n",
    "processed_classes = set()\n",
    "\n",
    "def clean_identifier(text):\n",
    "    \"\"\"Generate safe URI component\"\"\"\n",
    "    if pd.isna(text) or text in ['None', 'nan']:\n",
    "        return \"unknown\"\n",
    "    return re.sub(r'[^a-zA-Z0-9]', '', str(text).replace(' ', ''))[:50]\n",
    "\n",
    "def get_dynamic_mapping(entity_key):\n",
    "    \"\"\"Generate ontology mappings with base URI\"\"\"\n",
    "    clean_key = ''.join([w.capitalize() for w in re.split('[^a-zA-Z0-9]', entity_key)])\n",
    "    return {\n",
    "        \"class_uri\": f\"http://purl.obolibrary.org/obo/mcro.owl#{clean_key}\",\n",
    "        \"predicate_uri\": f\"http://purl.obolibrary.org/obo/mcro.owl#has{clean_key}\"\n",
    "    }\n",
    "\n",
    "def extract_hf_entities(text):\n",
    "    try:\n",
    "        prompt = f\"\"\"Extract metadata strictly using terms defined in the MCRO Ontology:\n",
    "        http://purl.obolibrary.org/obo/mcro.owl\n",
    "        \n",
    "Include only entities that clearly correspond to existing MCRO classes or properties.\n",
    "Avoid adding new or ad-hoc terms. Use exact labels from the ontology where applicable.\n",
    "\n",
    "Valid categories include: Model, Dataset, Metric, TrainingProcedure, EvaluationResult, Configuration, etc.\n",
    "\n",
    "Return a valid JSON object ONLY, no explanation. Example:\n",
    "{{\"dataset\": \"Wikipedia\", \"architecture\": \"Transformer\"}}\n",
    "\n",
    "Model card text:\n",
    "{text[:10000]}\"\"\"\n",
    "\n",
    "        genai.configure(api_key=GTOKEN)\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "        response = model.generate_content(prompt)\n",
    "\n",
    "        # Extract JSON block\n",
    "        json_str = response.text.strip()\n",
    "        if \"```json\" in json_str:\n",
    "            json_str = json_str.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        \n",
    "        # Basic JSON sanity check\n",
    "        if not json_str.startswith(\"{\") or not json_str.endswith(\"}\"):\n",
    "            raise ValueError(\"Invalid JSON structure\")\n",
    "\n",
    "        # Try parsing directly\n",
    "        return json.loads(json_str)\n",
    "    \n",
    "    except json.JSONDecodeError as je:\n",
    "        print(f\"JSON Decode Error: {str(je)} - attempting repair\")\n",
    "        try:\n",
    "            # Attempt to fix common JSON issues\n",
    "            json_str = re.sub(r',\\s*}', '}', json_str)  # remove trailing commas\n",
    "            json_str = re.sub(r',\\s*]', ']', json_str)\n",
    "            return json.loads(json_str)\n",
    "        except Exception as je2:\n",
    "            print(f\"Repair failed: {str(je2)}\")\n",
    "            return {}\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Extraction error: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def generate_hf_triples(model_data):\n",
    "    \"\"\"Generate RDF triples with ontology alignment\"\"\"\n",
    "    global processed_classes\n",
    "    triples = []\n",
    "    model_id = model_data.get('id', 'unknown')\n",
    "    model_uri = f\"http://purl.obolibrary.org/obo/mcro.owl#{clean_identifier(model_id)}\"\n",
    "    \n",
    "    # Base model type assertion\n",
    "    triples.append({\n",
    "        \"s\": model_uri,\n",
    "        \"p\": \"rdf:type\",\n",
    "        \"o\": \"http://purl.obolibrary.org/obo/mcro.owl#Model\"\n",
    "    })\n",
    "\n",
    "    if \"entities\" not in model_data:\n",
    "        return triples\n",
    "\n",
    "    for key, value in model_data[\"entities\"].items():\n",
    "        if not value or key.lower() in {'id', 'model'}:\n",
    "            continue\n",
    "\n",
    "        mapping = get_dynamic_mapping(key)\n",
    "        values = value if isinstance(value, list) else [value]\n",
    "\n",
    "        for val in values:\n",
    "            if pd.isna(val) or str(val).lower() in {'none', 'null', 'nan'}:\n",
    "                continue\n",
    "\n",
    "            # Create entity URI based on key only\n",
    "            entity_uri = f\"{model_uri}-{clean_identifier(key)}\"\n",
    "            \n",
    "            # Add core triples\n",
    "            triples.extend([\n",
    "                {\"s\": model_uri, \"p\": mapping['predicate_uri'], \"o\": entity_uri},\n",
    "                {\"s\": entity_uri, \"p\": \"rdf:type\", \"o\": mapping['class_uri']},\n",
    "                {\"s\": entity_uri, \"p\": \"dul:hasParameterDataValue\", \"o\": str(val)}\n",
    "            ])\n",
    "            \n",
    "            # Add class hierarchy once per class\n",
    "            if mapping['class_uri'] not in processed_classes:\n",
    "                triples.append({\n",
    "                    \"s\": mapping['class_uri'],\n",
    "                    \"p\": \"rdfs:subClassOf\",\n",
    "                    \"o\": \"http://purl.obolibrary.org/obo/mcro.owl#Component\"\n",
    "                })\n",
    "                processed_classes.add(mapping['class_uri'])\n",
    "\n",
    "    return triples\n",
    "\n",
    "def process_huggingface_models(limit=10):\n",
    "    \"\"\"Process models and generate RDF triples\"\"\"\n",
    "    api = HfApi(token=HFTOKEN)\n",
    "    models = list(api.list_models(sort=\"downloads\", direction=-1, limit=limit))\n",
    "    all_triples = []\n",
    "\n",
    "    for idx, model in enumerate(models):\n",
    "        try:\n",
    "            card = ModelCard.load(model.modelId, token=HFTOKEN)\n",
    "            entities = extract_hf_entities(card.text)\n",
    "            \n",
    "            if not entities:\n",
    "                print(f\"Skipping {model.modelId} - no entities found\")\n",
    "                continue\n",
    "\n",
    "            model_data = {\"id\": model.modelId, \"entities\": entities}\n",
    "            triples = generate_hf_triples(model_data)\n",
    "            all_triples.extend(triples)\n",
    "\n",
    "            if idx % 5 == 0:\n",
    "                print(f\"Processed {idx+1}/{len(models)}: {model.modelId}\")\n",
    "                print(f\"Generated {len(triples)} triples from {len(entities)} entities\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {model.modelId}: {str(e)}\")\n",
    "\n",
    "    with open(\"extracted_triples.json\", \"w\") as f:\n",
    "        json.dump(all_triples, f, indent=2)\n",
    "\n",
    "    print(\"\\n=== STATISTICS ===\")\n",
    "    print(f\"Total models processed: {len(models)}\")\n",
    "    print(f\"Total triples generated: {len(all_triples)}\")\n",
    "    return all_triples\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== TRIPLE GENERATION STARTED ===\")\n",
    "    triples = process_huggingface_models(limit=10)\n",
    "    print(\"\\n=== COMPLETED ===\")\n",
    "    print(f\"Final triple count: {len(triples)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
